{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a899e893",
   "metadata": {},
   "source": [
    "# Optimización de Conjuntos de Datos para ML - 100473223 - Juan Leal Aliaga\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Modificaciones Planteadas\n",
    "\n",
    "### 1.1 Síntesis de Atributos (Programación Genética)\n",
    "- **Objetivo**: Crear 4 nuevas features mediante árboles de expresiones matemáticas\n",
    "- **Operadores**: add, sub, mul, div, sqrt, square, log, sin, cos, tanh\n",
    "- **Terminales**: Variables originales X₀...Xₙ y constantes [-5, 5]\n",
    "\n",
    "### 1.2 Reducción de Dimensionalidad (Feature Selection)\n",
    "- **Objetivo**: Seleccionar subconjunto óptimo de features (originales + generadas)\n",
    "- **Método**: Algoritmo Genético con codificación binaria\n",
    "- **Rango**: Entre 3 y 15 features seleccionadas\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Técnicas de Computación Evolutiva\n",
    "\n",
    "### 2.1 Programación Genética (GP)\n",
    "**Población**: 100 individuos  \n",
    "**Representación**: Lista de árboles  \n",
    "**Profundidad**: 2-5 niveles  \n",
    "\n",
    "**Operadores Genéticos**:\n",
    "- Cruce a nivel de subárbol (prob. 0.8)\n",
    "- Mutación de nodos/valores (prob. 0.2)\n",
    "- Reemplazo aleatorio de árboles completos\n",
    "\n",
    "### 2.2 Algoritmo Genético (GA) para Feature Selection\n",
    "**Población**: 30 individuos  \n",
    "**Representación**: Vector binario [1,0,1,1,0...]  \n",
    "\n",
    "**Operadores Genéticos**:\n",
    "- Cruce uniforme (prob. 0.8)\n",
    "- Mutación por bit-flip 1-3 bits (prob. 0.3)\n",
    "- Selección por torneo tamaño 3\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Codificación, Operadores y Función de Fitness\n",
    "\n",
    "### 3.1 Codificación en GP\n",
    "\n",
    "- individuo = [árbol_1, árbol_2, árbol_3, árbol_4]\n",
    "- Ejemplo de árbol: (X₀ + sqrt(X₁))\n",
    "\n",
    "### 3.2 Función de Fitness (GP)\n",
    "\n",
    "fitness = MSE_cv + λ · complejidad\n",
    "\n",
    "Donde:\n",
    "- MSE_cv: Error cuadrático medio en 3-fold cross-validation\n",
    "- Complejidad: Suma de nodos de todos los árboles\n",
    "- λ = 0.001, penalización por bloat (Excesiva expansión del árbol)\n",
    "\n",
    "### 3.3 Función de Fitness (Feature Selection)\n",
    "fitness = MSE_validation + 0.01 · n_features\n",
    "\n",
    "Donde:\n",
    "- MSE_validation: Error en conjunto de validación (20% train)\n",
    "- n_features: Número de features seleccionadas\n",
    "- Restricción: mínimo 2 features\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Intentos Fallidos\n",
    "\n",
    "### 4.1 Penalizaciones Excesivas\n",
    "- Penalizaciones altas (λ=0.01) causaban árboles muy pequeños\n",
    "- Resultados pobres en test set\n",
    "### 4.2 Overfitting en GP\n",
    "- Sin penalización, árboles crecían demasiado\n",
    "- Buen rendimiento en train, malo en test\n",
    "### 4.3 Selección de Features sin Restricción\n",
    "- Individuos seleccionaban pocas features (1-2)\n",
    "- Resultados inestables y pobres\n",
    "### 4.4 Cambios de estrategia\n",
    "- Diferentes funciones (pow, exp, trigonométricas...)\n",
    "- Uso entre 3, 4, 5 modelos pero elección random\n",
    "- Train/Validation en lugar de cv\n",
    "- \n",
    "---\n",
    "\n",
    "## 4. Resultados Obtenidos\n",
    "\n",
    "### 4.1 Configuración Experimental\n",
    "- **Modelos entrenados**: Uso Ensemble de Ridge y Random Forest tanto en GP como SE\n",
    "- **Datasets**: California Housing (20,640 × 8) y Diabetes (442 × 10)\n",
    "- **Tiempos**: 20 minutos y 1 hora\n",
    "- **Modelos evaluados**: 16 (Ridge, LinearReg, RF, XGBoost, SVR, etc.)\n",
    "- **Métricas**: MAE y MSE en test set (20%)\n",
    "\n",
    "### 4.2 Hallazgos Principales\n",
    "\n",
    "**Mejoras Consistentes**: \n",
    "- La mayoría de modelos mejoraron en ambos datasets\n",
    "- Se intenta que funcione correctamente con modelos de todos los tipos: Lineales, ensembles,...\n",
    "\n",
    "**Reducción Efectiva**: \n",
    "- De 8-10 features originales → 6-8 features optimizadas\n",
    "- Manteniendo o mejorando el rendimiento\n",
    "\n",
    "**Generalización**:\n",
    "- Las transformaciones funcionan en múltiples tipos de modelos\n",
    "- No sobreajuste: mejoras en test, no solo en train\n",
    "\n",
    "**Actuación del Early-Stopping**:\n",
    "- Para mi configuración final, el early-stopping no suele actuar ya que cada generación tarda bastante\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Conclusiones\n",
    "\n",
    "### 5.1 Estrategias Clave Implementadas\n",
    "- **Early stopping** con validación interna (50/30 gens)\n",
    "- **Protección robusta**: Clipping, NaN/Inf handling, división protegida\n",
    "- **Regularización**: Ridge + RF\n",
    "- **Evaluación robusta**: Cross-validation\n",
    "\n",
    "\n",
    "### 5.2 Trabajo Futuro\n",
    "1. **Paralelización**: Evaluación paralela de individuos con multiprocessing\n",
    "2. **Multi-objetivo**: Optimizar simultáneamente MSE, MAE y complejidad (Pareto)\n",
    "3. **Memoización**: Cachear evaluaciones de subárboles repetidos\n",
    "4. **Transfer learning**: Reutilizar features entre datasets similares\n",
    "\n",
    "### 5.3 Conclusión Final y Resultados (Benchmark)\n",
    "Las mejoras consistentes obtenidas en múltiples modelos y datasets validan la efectividad del enfoque híbrido **GP + GA**, posicionándolo como una solución viable para preprocesamiento automático en proyectos reales de Machine Learning.\n",
    "\n",
    "Aquí tienes tu texto en **formato Markdown** bien estructurado y legible:\n",
    "\n",
    "---\n",
    "\n",
    "## Resumen completo --> Todos los modelos con Ensemble\n",
    "\n",
    "| Modelo           | MAE Base | MAE Opt | Mejora MAE   | MSE Base | MSE Opt | Mejora MSE   |\n",
    "| ---------------- | -------- | ------- | ------------ | -------- | ------- | ------------ |\n",
    "| KNeighbors       | 0.8128   | 0.3880  | **52.26 %**  | 1.1187   | 0.3386  | **69.73 %**  |\n",
    "| MLP              | 0.6506   | 0.4080  | **37.28 %**  | 0.7129   | 0.3602  | **49.47 %**  |\n",
    "| SVR              | 0.8600   | 0.5976  | **30.50 %**  | 1.3320   | 0.6877  | **48.37 %**  |\n",
    "| HuberRegressor   | 0.5876   | 0.4889  | **16.79 %**  | 0.7119   | 0.4671  | **34.38 %**  |\n",
    "| LinearRegression | 0.5332   | 0.4958  | **7.02 %**   | 0.5559   | 0.4569  | **17.82 %**  |\n",
    "| Ridge            | 0.5332   | 0.4957  | **7.03 %**   | 0.5558   | 0.4569  | **17.80 %**  |\n",
    "| BayesianRidge    | 0.5332   | 0.4958  | **7.02 %**   | 0.5556   | 0.4569  | **17.77 %**  |\n",
    "| DecisionTree     | 0.4547   | 0.4168  | **8.34 %**   | 0.4952   | 0.4424  | **10.68 %**  |\n",
    "| AdaBoost         | 0.6498   | 0.6086  | **6.34 %**   | 0.6145   | 0.5722  | **6.87 %**   |\n",
    "| GradientBoosting | 0.3716   | 0.3587  | **3.48 %**   | 0.2940   | 0.2852  | **2.99 %**   |\n",
    "| Bagging          | 0.3279   | 0.3158  | **3.68 %**   | 0.2559   | 0.2499  | **2.34 %**   |\n",
    "| RandomForest     | 0.3275   | 0.3158  | **3.59 %**   | 0.2554   | 0.2495  | **2.30 %**   |\n",
    "| ExtraTrees       | 0.3270   | 0.3207  | **1.93 %**   | 0.2539   | 0.2484  | **2.16 %**   |\n",
    "| XGBoost          | 0.3096   | 0.3100  | **–0.12 %**  | 0.2226   | 0.2301  | **–3.35 %**  |\n",
    "| Lasso            | 0.7616   | 0.9061  | **–18.97 %** | 0.9380   | 1.3107  | **–39.73 %** |\n",
    "| ElasticNet       | 0.6763   | 0.8387  | **–24.02 %** | 0.7646   | 1.1262  | **–47.31 %** |\n",
    "\n",
    "---\n",
    "\n",
    "## ESTADÍSTICAS GENERALES CON ENSEMBLE\n",
    "\n",
    "* **Modelos que mejoraron MAE:** 13 / 16\n",
    "* **Modelos que mejoraron MSE:** 13 / 16\n",
    "* **Mejor mejora MAE:** 52.26 % *(KNeighbors)*\n",
    "* **Mejor mejora MSE:** 69.73 % *(KNeighbors)*\n",
    "* **Mejora promedio MAE:** 8.88 %\n",
    "* **Mejora promedio MSE:** 12.02 %\n",
    "* **Evaluación con Ensemble:** *Ridge + RandomForest (promedio)*\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Anexo de IA Generativa\n",
    "\n",
    "### 6.1 Uso de IA Generativa en el Proyecto\n",
    "\n",
    "Durante el desarrollo de este proyecto se utilizó **IA Generativa** (Claude, ChatGPT, Codex...) para:\n",
    "\n",
    "#### Tareas Realizadas:\n",
    "1. **Debugging de código**: Identificar errores en la evaluación de fitness\n",
    "2. **Optimización de rendimiento**: Sugerencias para reducir tiempo de ejecución\n",
    "3. **Exploración de hiperparámetros**: Recomendaciones de valores iniciales\n",
    "4. **Generación de visualizaciones**: Código para gráficos de evolución del fitness\n",
    "\n",
    "### 6.2 Ejemplos de Prompts Utilizados\n",
    "\n",
    "#### Prompt 1: Debugging\n",
    "```\n",
    "\"Tengo un error NaN en la evaluación de fitness de mi GP. \n",
    "El código es el siguiente: [...]. ¿Cómo puedo proteger contra \n",
    "divisiones por cero y valores infinitos?\"\n",
    "```\n",
    "\n",
    "**Resultado obtenido**:\n",
    "Solución implementada\n",
    "\n",
    "#### Prompt 2: Optimización\n",
    "```\n",
    "\"Mi algoritmo genético para feature selection es muy lento. \n",
    "Usa cross-validation 5-fold en cada evaluación. ¿Cómo puedo \n",
    "acelerar sin perder demasiada precisión?\"\n",
    "```\n",
    "\n",
    "**Resultado obtenido**:\n",
    "- Usar validación simple en lugar de CV durante la búsqueda\n",
    "- Aplicar CV solo al mejor individuo final\n",
    "- Reducir population_size de 50 a 30\n",
    "- Implementar early stopping agresivo (30 generaciones)\n",
    "\n",
    "#### Prompt 3: Estrategia de Reparto de Tiempo\n",
    "```\n",
    "\"Tengo maxtime=3600 segundos. ¿Cómo debería repartir el tiempo \n",
    "entre la fase de GP (síntesis) y GA (selección) para maximizar \n",
    "la mejora final?\"\n",
    "```\n",
    "\n",
    "**Resultado obtenido**:\n",
    "- 70% del tiempo para GP (síntesis de features)\n",
    "- 30% del tiempo para GA (selección)\n",
    "- Justificación: la síntesis es más compleja y beneficia más\n",
    "\n",
    "#### Prompt 4: Comparación de Modelos\n",
    "```\n",
    "\"Tengo resultados de 17 modelos con/sin optimización. \n",
    "Dame código para crear una tabla ordenada por mejora en MSE\"\n",
    "```\n",
    "\n",
    "**Resultado**: Código del bloque de análisis comparativo usado en el notebook\n",
    "\n",
    "#### Prompt 5: Visualización de Convergencia\n",
    "```\n",
    "\"Quiero graficar la evolución del mejor fitness a lo largo de \n",
    "las generaciones. ¿Cómo visualizo el progreso del GP?\"\n",
    "```\n",
    "\n",
    "**Resultado**: \n",
    "Código base de plot...\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
